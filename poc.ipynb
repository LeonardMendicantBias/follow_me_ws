{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1c2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4eadf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import ClassVar\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import imageio\n",
    "import sqlite3\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from sensor_msgs.msg import PointCloud2\n",
    "from sensor_msgs.msg import Image as ROS_Image\n",
    "import sensor_msgs_py.point_cloud2 as pc2\n",
    "from rclpy.serialization import deserialize_message\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from torchvision.models import resnet18 as resnet, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from queue import Queue\n",
    "\n",
    "from src.follow_me.follow_me.tracker import Tracker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7977905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rosout\n",
      "/events/write_split\n",
      "/diagnostics\n",
      "/parameter_events\n",
      "/velodyne_points\n",
      "/joint_states\n",
      "/scan\n",
      "/tf_static\n",
      "/velodyne_packets\n",
      "/camera/camera/color/camera_info\n",
      "/camera/camera/extrinsics/depth_to_color\n",
      "/camera/camera/depth/metadata\n",
      "/camera/camera/depth/camera_info\n",
      "/camera/camera/depth/image_rect_raw\n",
      "/camera/camera/color/metadata\n",
      "/camera/camera/color/image_raw\n",
      "/odom\n",
      "/robot_description\n",
      "/tf\n",
      "/tracer_status\n"
     ]
    }
   ],
   "source": [
    "ds = \"v1\"\n",
    "\n",
    "conn = sqlite3.connect(f\"./{ds}/{ds}_0.db3\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM topics\")\n",
    "topic_info = cursor.fetchall()\n",
    "for topic in topic_info:\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2f018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Info: (16, '/camera/camera/color/image_raw', 'sensor_msgs/msg/Image', 'cdr', '- history: 3\\n  depth: 0\\n  reliability: 1\\n  durability: 1\\n  deadline:\\n    sec: 9223372036\\n    nsec: 854775807\\n  lifespan:\\n    sec: 9223372036\\n    nsec: 854775807\\n  liveliness: 1\\n  liveliness_lease_duration:\\n    sec: 9223372036\\n    nsec: 854775807\\n  avoid_ros_namespace_conventions: false')\n"
     ]
    }
   ],
   "source": [
    "topic_name = \"/camera/camera/color/image_raw\"\n",
    "cursor.execute(f\"SELECT * FROM topics WHERE name='{topic_name}'\")\n",
    "topic_info = cursor.fetchone()\n",
    "\t\n",
    "if not topic_info:\n",
    "\tprint(\"Topic not found.\")\n",
    "\t\n",
    "print(\"Topic Info:\", topic_info)\n",
    "topic_id = topic_info[0]  # 'id' is the first column in topics\n",
    "\n",
    "# Step 2: Get all messages for that topic\n",
    "cursor.execute(\"SELECT * FROM messages WHERE topic_id = ?\", (topic_id,))\n",
    "messages = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b34b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11n-pose.pt\")\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0bb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/follow_me_ws/src/follow_me/follow_me/tracker.py:155: RuntimeWarning: invalid value encountered in divide\n",
      "  avg_scores = np.divide(\n"
     ]
    }
   ],
   "source": [
    "def draw_img(target_id, image, result):\n",
    "\tannotated = image.copy()\n",
    "\tfor idx, (bbox, conf) in enumerate(zip(result.boxes.xywh, result.boxes.conf)):\n",
    "\t\tx, y, w, h = map(int, bbox)\n",
    "\t\t\n",
    "\t\tcv2.rectangle(annotated, \n",
    "\t\t\t(int(x-w/2), int(y-h/2)), (int(x+w/2), int(y+h/2)),\n",
    "\t\t\t(255, 0, 0) if target_id==idx else (0, 255, 0), 2\n",
    "\t\t)\n",
    "\t\t# cv2.putText(annotated, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "\treturn annotated\n",
    "\n",
    "bridge = CvBridge()\n",
    "tracker = Tracker((256, 448))\n",
    "\n",
    "conf_threshold = .6\n",
    "\n",
    "is_following = False\n",
    "frames = []\n",
    "# for idx in range(450, 451):\n",
    "# for idx in range(785, 786):\n",
    "# for idx in range(1800, 1810):\n",
    "for idx in range(1700, 2100):\n",
    "# for idx in range(1550, len(messages)):\n",
    "\tmsg_id, topic_id, timestamp, data = messages[idx]\n",
    "\trgb_image = deserialize_message(data, ROS_Image)\n",
    "\tcv_image = bridge.imgmsg_to_cv2(rgb_image, desired_encoding='bgr8')\n",
    "\th, w = cv_image.shape[:2]\n",
    "\n",
    "\tresults = model(\n",
    "\t\tcv_image,\n",
    "\t\tconf=conf_threshold,\n",
    "\t\tverbose=False,\n",
    "\t)\n",
    "\tresult = results[0].cpu()\n",
    "\t# result.show()\n",
    "\n",
    "\tif len(result.boxes) == 0:\n",
    "\t\tframes.append(cv_image)\n",
    "\t\tcontinue\n",
    "\tif not torch.any(result.keypoints.conf > 0.5):\n",
    "\t\tframes.append(cv_image)\n",
    "\t\tcontinue\n",
    "\t\n",
    "\tbboxes = result.boxes.xywh.numpy()\n",
    "\tkpts = result.keypoints.xy.numpy()\n",
    "\tconfs = result.keypoints.conf.numpy()\n",
    "\t# print(len(bboxes), len(kpts))\n",
    "\t# print(result.boxes.conf.numpy())\n",
    "\t\n",
    "\tall_features, visible_part = tracker.process_crop(\n",
    "\t\tcv_image, bboxes, kpts, confs\n",
    "\t)\n",
    "\t\n",
    "\tif not is_following:\n",
    "\t\tis_following = True\n",
    "\t\txy = bboxes[:, :2]\n",
    "\t\tdist = xy - np.array([w/2, h/2])\n",
    "\t\tdist = np.abs(dist).sum(-1)\n",
    "\t\ttarget_id = np.argmin(dist)\n",
    "\telse:\n",
    "\t\ttarget_id = tracker.identify(\n",
    "\t\t\tall_features.cpu().detach(),\n",
    "\t\t\tvisible_part.cpu().detach(),\n",
    "\t\t\tthreshold=0.5\n",
    "\t\t)\n",
    "\t\tif target_id is None: target_id = -1\n",
    "\n",
    "\tif target_id != -1:\n",
    "\t\ttracker.update(target_id, all_features, visible_part)\n",
    "\t# tracker.identify(\n",
    "\t# \tall_features.cpu().detach(),\n",
    "\t# \tvisible_part.cpu().detach()\n",
    "\t# )\n",
    "\tannotated = draw_img(target_id, cv_image, result)\n",
    "\tframes.append(annotated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b94cc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimsave(\"./detections.gif\", frames, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60678f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
